# -*- coding: utf-8 -*-
"""Final_proj_(FINAL).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8F-2ZS6FuceQ6esxN31ENzgXAiPF83F
"""

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Read the CSV file into a DataFrame
df = pd.read_csv('/content/mhealth_raw_data.csv')
# Remove rows with missing values (NaNs)
df = df.dropna()
# Get unique values of 'Activity' column
unique_activities = df['Activity'].unique()

# Get unique values of 'subject' column
unique_subjects = df['subject'].unique()

# Print unique values
print("Unique activities:", unique_activities)
print("Unique subjects:", unique_subjects)

# Initialize an empty list to store subsets
subsets = []

# Iterate over unique activity categories
for activity, count in df.groupby('Activity').size().items():
    # Sample an equal number of instances for each activity category
    subset = df[df['Activity'] == activity].sample(df.groupby('Activity').size().min())
    # Append the subset to the list of subsets
    subsets.append(subset)

# Concatenate all subsets into a single DataFrame
df = pd.concat(subsets)

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Fit and transform 'subject' column
df['subject'] = label_encoder.fit_transform(df['subject']) + 1

# Drop the 'Activity' column to get features
X = df.drop(columns=['Activity'])

# Get the column names before scaling
cols = X.columns

# Initialize StandardScaler
scaler = StandardScaler()

# Fit and transform the features
X_scaled = scaler.fit_transform(X)

# Convert the scaled features back to a DataFrame
X = pd.DataFrame(X_scaled, columns=cols)

# Extract the target variable 'Activity'
y = df['Activity']

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)


plt.figure(figsize=(10, 8))
for activity_label in np.unique(y):
    plt.scatter(X_pca[y == activity_label, 0], X_pca[y == activity_label, 1],
                label=f'Activity {activity_label}', alpha=0.7)

plt.xlabel('Z1')
plt.ylabel('Z2')
plt.legend()
plt.grid(True)
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
X_train

from sklearn.model_selection import GridSearchCV
# Define the parameter grid
param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [0.1, 0.01, 0.001],
}
# Support Vector Machine (SVM)
SVM = SVC(kernel='rbf', random_state=42)
grid_search = GridSearchCV(estimator=SVM, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_svm_model = SVC(kernel='rbf', random_state=42, **best_params)
best_svm_model.fit(X_train, y_train)
best_svm_model_accuracy = best_svm_model.score(X_test, y_test)


# Train SVM model
SVM.fit(X_train, y_train)

# Predictions using SVM model
predictions_svm = SVM.predict(X_test)

# Calculate accuracy
accuracy_svm = accuracy_score(y_test, predictions_svm)
cv_scores_svm = cross_val_score(SVM, X_train, y_train, cv=5)
# Print SVM accuracy
print("SVM Accuracy:", accuracy_svm)
print("Best hyperparameters:", best_params)
print("Best SVM model accuracy:", best_svm_model_accuracy)

print("Cross-validation accuracy (SVM):", np.mean(cv_scores_svm))
# Logistic Regression Model
LogisticRegressionModel = LogisticRegression(random_state=42, max_iter=1000)

# Cross-validation scores
cv_scores = cross_val_score(LogisticRegressionModel, X_train, y_train, cv=5)

# Train logistic regression model
LogisticRegressionModel.fit(X_train, y_train)

# Predictions using logistic regression model
y_pred_lr = LogisticRegressionModel.predict(X_test)

# Calculate accuracy, precision, recall, and F1-score
accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr, average='weighted')
recall_lr = recall_score(y_test, y_pred_lr, average='weighted')
f1_lr = f1_score(y_test, y_pred_lr, average='weighted')

# Calculate mean cross-validation score
mean_cv_score_lr = np.mean(cv_scores)

# Confusion matrix
conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)

# Print logistic regression model evaluation metrics
print("Logistic Regression accuracy:", accuracy_lr)
print("Cross-validation accuracy:", mean_cv_score_lr)
print("Precision:", precision_lr)
print("Recall:", recall_lr)
print("F1-score:", f1_lr)
print("Confusion Matrix:")
print(conf_matrix_lr)

# Linear Regression Model
model = LinearRegression()

# Cross-validation scores for linear regression model
cv_scores_lr = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')

# Train linear regression model
model.fit(X_train, y_train)

# Predictions using linear regression model
y_pred_lr = model.predict(X_test)

# Calculate mean squared error
mse_lr = mean_squared_error(y_test, y_pred_lr)
mean_cv_mse_lr = -np.mean(cv_scores_lr)

# Print linear regression model evaluation metrics
print("Mean Squared Error:", mse_lr)
print("Cross-Validation Mean Squared Error:", mean_cv_mse_lr)

# K-Nearest Neighbors (KNN) Classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5)

# Cross-validation scores for KNN classifier
cv_scores_knn = cross_val_score(knn_classifier, X_train, y_train, cv=5)

# Train KNN classifier
knn_classifier.fit(X_train, y_train)

# Predictions using KNN classifier
y_pred_knn = knn_classifier.predict(X_test)

# Calculate accuracy, precision, recall, and F1-score for KNN classifier
accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn, average='weighted')
recall_knn = recall_score(y_test, y_pred_knn, average='weighted')
f1_knn = f1_score(y_test, y_pred_knn, average='weighted')

# Calculate mean cross-validation score for KNN classifier
mean_cv_score_knn = np.mean(cv_scores_knn)

# Confusion matrix for KNN classifier
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)

# Print KNN classifier evaluation metrics
print("KNN accuracy:", accuracy_knn)
print("Cross-validation accuracy:", mean_cv_score_knn)
print("Precision:", precision_knn)
print("Recall:", recall_knn)
print("F1-score:", f1_knn)
print("Confusion Matrix:")
print(conf_matrix_knn)

# Neural Network Model
model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(13, activation='softmax')
])

# Compile the model
model.compile(optimizer='sgd',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=9, batch_size=32)

# Evaluate the model on test data
test_loss, test_acc = model.evaluate(X_test, y_test)